{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and test data submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#IMPORTING REQUIRED LIBRARIES\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_submission.csv.zip', 'test', 'train']\n"
     ]
    }
   ],
   "source": [
    "def load_df(csv_path='./input/train/train.csv', nrows=None):\n",
    "    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "    \n",
    "    df = pd.read_csv(csv_path, \n",
    "                     converters={column: json.loads for column in JSON_COLUMNS}, \n",
    "                     dtype={'fullVisitorId': 'str'}, # Important!!\n",
    "                     nrows=nrows)\n",
    "    \n",
    "    for column in JSON_COLUMNS:\n",
    "        column_as_df = json_normalize(df[column])\n",
    "        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n",
    "        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n",
    "    print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "print(os.listdir(\"./input/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train.csv. Shape: (903653, 55)\n",
      "Loaded test.csv. Shape: (804684, 53)\n",
      "Wall time: 10min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df = load_df()\n",
    "test_df = load_df(\"./input/test/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['channelGrouping', 'date', 'fullVisitorId', 'sessionId',\n",
       "       'socialEngagementType', 'visitId', 'visitNumber', 'visitStartTime',\n",
       "       'device.browser', 'device.browserSize', 'device.browserVersion',\n",
       "       'device.deviceCategory', 'device.flashVersion', 'device.isMobile',\n",
       "       'device.language', 'device.mobileDeviceBranding',\n",
       "       'device.mobileDeviceInfo', 'device.mobileDeviceMarketingName',\n",
       "       'device.mobileDeviceModel', 'device.mobileInputSelector',\n",
       "       'device.operatingSystem', 'device.operatingSystemVersion',\n",
       "       'device.screenColors', 'device.screenResolution', 'geoNetwork.city',\n",
       "       'geoNetwork.cityId', 'geoNetwork.continent', 'geoNetwork.country',\n",
       "       'geoNetwork.latitude', 'geoNetwork.longitude', 'geoNetwork.metro',\n",
       "       'geoNetwork.networkDomain', 'geoNetwork.networkLocation',\n",
       "       'geoNetwork.region', 'geoNetwork.subContinent', 'totals.bounces',\n",
       "       'totals.hits', 'totals.newVisits', 'totals.pageviews', 'totals.visits',\n",
       "       'trafficSource.adContent',\n",
       "       'trafficSource.adwordsClickInfo.adNetworkType',\n",
       "       'trafficSource.adwordsClickInfo.criteriaParameters',\n",
       "       'trafficSource.adwordsClickInfo.gclId',\n",
       "       'trafficSource.adwordsClickInfo.isVideoAd',\n",
       "       'trafficSource.adwordsClickInfo.page',\n",
       "       'trafficSource.adwordsClickInfo.slot', 'trafficSource.campaign',\n",
       "       'trafficSource.isTrueDirect', 'trafficSource.keyword',\n",
       "       'trafficSource.medium', 'trafficSource.referralPath',\n",
       "       'trafficSource.source'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_df(df):\n",
    "    if df['df['totals.transactionRevenue']']:\n",
    "        target = df['totals.transactionRevenue'].fillna(0).astype(float)\n",
    "    target = target.apply(lambda x: np.log1p(x))\n",
    "    del df['totals.transactionRevenue']\n",
    "    \n",
    "    columns_to_remove = [col for col in df.columns if df[col].nunique() == 1]\n",
    "    print(\"Nb. of variables with unique value: {}\".format(len(columns_to_remove)))\n",
    "    \n",
    "    for col in columns_to_remove:\n",
    "        if set(['not available in demo dataset']) ==  set(df[col].unique()): continue\n",
    "        print(col, df[col].dtypes, df[col].unique())\n",
    "    \n",
    "    df['totals.bounces'] = df['totals.bounces'].fillna('0')\n",
    "    df['totals.newVisits'] = df['totals.newVisits'].fillna('0')\n",
    "    df['trafficSource.adwordsClickInfo.isVideoAd'] = df['trafficSource.adwordsClickInfo.isVideoAd'].fillna(True)\n",
    "    df['trafficSource.isTrueDirect'] = df['trafficSource.isTrueDirect'].fillna(False)\n",
    "    \n",
    "    columns = [col for col in df.columns if df[col].nunique() > 1]\n",
    "    df = df[columns]\n",
    "\n",
    "    return df\n",
    "\n",
    "test_df.columns\n",
    "\n",
    "#train = clean_df(train_df)\n",
    "#test = clean_df(test_df)\n",
    "\n",
    "#train.head\n",
    "\n",
    "#trn_len = train.shape[0]\n",
    "#merged_df = pd.concat([train, test])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-5550d3bee1f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmerged_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'diff_visitId_time'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'visitId'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'visitStartTime'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'diff_visitId_time'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmerged_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'diff_visitId_time'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'visitId'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sessionId'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'merged_df' is not defined"
     ]
    }
   ],
   "source": [
    "merged_df['diff_visitId_time'] = merged_df['visitId'] - merged_df['visitStartTime']\n",
    "merged_df['diff_visitId_time'] = (merged_df['diff_visitId_time'] != 0).astype(int)\n",
    "del merged_df['visitId']\n",
    "del merged_df['sessionId']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-1a0cb62698eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mformat_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'%Y%m%d'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmerged_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'formated_date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'month'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'formated_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'quarter_month'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'formated_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'merged_df' is not defined"
     ]
    }
   ],
   "source": [
    "## DATES\n",
    "\n",
    "format_str = '%Y%m%d' \n",
    "merged_df['formated_date'] = merged_df['date'].apply(lambda x: datetime.strptime(str(x), format_str))\n",
    "merged_df['month'] = merged_df['formated_date'].apply(lambda x:x.month)\n",
    "merged_df['quarter_month'] = merged_df['formated_date'].apply(lambda x:x.day//8)\n",
    "merged_df['day'] = merged_df['formated_date'].apply(lambda x:x.day)\n",
    "merged_df['weekday'] = merged_df['formated_date'].apply(lambda x:x.weekday())\n",
    "\n",
    "del merged_df['date']\n",
    "del merged_df['formated_date']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_df['totals.hits'] = merged_df['totals.hits'].astype(int)\n",
    "merged_df['mean_hits_per_day'] = merged_df.groupby(['day'])['totals.hits'].transform('mean')\n",
    "del  merged_df['day']\n",
    "\n",
    "merged_df['formated_visitStartTime'] = merged_df['visitStartTime'].apply(\n",
    "    lambda x: time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(x)))\n",
    "merged_df['formated_visitStartTime'] = pd.to_datetime(merged_df['formated_visitStartTime'])\n",
    "merged_df['visit_hour'] = merged_df['formated_visitStartTime'].apply(lambda x: x.hour)\n",
    "\n",
    "del merged_df['visitStartTime']\n",
    "del merged_df['formated_visitStartTime']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## ENCODE CATEGORICAL VALUES\n",
    "\n",
    "for col in merged_df.columns:\n",
    "    if col in ['fullVisitorId', 'month', 'quarter_month', 'weekday', 'visit_hour', 'WoY']: continue\n",
    "    if merged_df[col].dtypes == object or merged_df[col].dtypes == bool:\n",
    "        merged_df[col], indexer = pd.factorize(merged_df[col])\n",
    "numerics = [col for col in merged_df.columns if 'totals.' in col]\n",
    "numerics += ['visitNumber', 'mean_hits_per_day', 'fullVisitorId']\n",
    "categorical_feats =  [col for col in merged_df.columns if col not in numerics]\n",
    "for col in categorical_feats:\n",
    "    merged_df[col] = merged_df[col].astype(int)\n",
    "#merged_df['fullVisitorId'] = merged_df['fullVisitorId'].astype(float)\n",
    "train_df = merged_df[:trn_len]\n",
    "test_df = merged_df[trn_len:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {'num_leaves': 300,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.005,\n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.8 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 1,\n",
    "         \"verbosity\": -1}\n",
    "         \n",
    " trn_cols = [col for col in train_df.columns if col not in ['fullVisitorId']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CV\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof = np.zeros(len(train_df))\n",
    "predictions = np.zeros(len(test_df))\n",
    "start = time.time()\n",
    "features = list(train_df[trn_cols].columns)\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, target.values)):\n",
    "    trn_data = lgb.Dataset(train_df.iloc[trn_idx][trn_cols], label=target.iloc[trn_idx], categorical_feature=categorical_feats)\n",
    "    val_data = lgb.Dataset(train_df.iloc[val_idx][trn_cols], label=target.iloc[val_idx], categorical_feature=categorical_feats)\n",
    "    \n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 100)\n",
    "    oof[val_idx] = clf.predict(train_df.iloc[val_idx][trn_cols], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(test_df[trn_cols], num_iteration=clf.best_iteration) / folds.n_splits\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
